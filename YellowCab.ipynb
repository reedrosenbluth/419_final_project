{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from Yellow Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taxidata = pd.read_csv(\"./data/test.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleandata = taxidata[(taxidata.pickup_longitude > -74.1) & (taxidata.pickup_longitude < -73.8)]\n",
    "cleandata = cleandata[(cleandata.pickup_latitude > 40.55) & (cleandata.pickup_latitude < 40.9)]\n",
    "\n",
    "cleandata = cleandata[(cleandata.dropoff_longitude > -74.1) & (cleandata.dropoff_longitude < -73.8)]\n",
    "cleandata = cleandata[(cleandata.dropoff_latitude > 40.55) & (cleandata.dropoff_latitude < 40.9)]\n",
    "\n",
    "# cleandata = taxidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "itrain, itest = train_test_split(xrange(cleandata.shape[0]), train_size = 0.8)\n",
    "mask=np.ones(cleandata.shape[0], dtype='int')\n",
    "mask[itrain] = 1\n",
    "mask[itest] = 0\n",
    "mask = (mask == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating hour feature...\n",
      "Creating minute feature...\n",
      "          hour  minute\n",
      "0            0       0\n",
      "1            0       0\n",
      "2            0       0\n",
      "3            0       0\n",
      "4            0       0\n",
      "5            0       0\n",
      "6            0       0\n",
      "7            0       0\n",
      "8            0       0\n",
      "9            0       0\n",
      "10           0       0\n",
      "11           0       0\n",
      "12           0       0\n",
      "13           0       0\n",
      "14           0       0\n",
      "15           0       0\n",
      "16           0       0\n",
      "17           0       0\n",
      "18           0       0\n",
      "19           0       0\n",
      "20           0       0\n",
      "21           0       0\n",
      "22           0       0\n",
      "23           0       0\n",
      "24           0       0\n",
      "25           0       0\n",
      "26           0       0\n",
      "27           0       0\n",
      "28           0       0\n",
      "29           0       0\n",
      "...        ...     ...\n",
      "10906828    23       6\n",
      "10906829    23      34\n",
      "10906830     1      45\n",
      "10906831     2       1\n",
      "10906832     2      31\n",
      "10906833     2      57\n",
      "10906834     3       6\n",
      "10906835     3      24\n",
      "10906836     3      52\n",
      "10906837     4       0\n",
      "10906838     4      16\n",
      "10906839     4      30\n",
      "10906840     4      46\n",
      "10906841     5      11\n",
      "10906842    19       9\n",
      "10906843    19      27\n",
      "10906844    19      38\n",
      "10906845    19      55\n",
      "10906846    20      14\n",
      "10906847    20      36\n",
      "10906848    20      53\n",
      "10906849    21      28\n",
      "10906850    22      36\n",
      "10906851    22      53\n",
      "10906852    23       0\n",
      "10906853    23      30\n",
      "10906854     0      15\n",
      "10906855     6      12\n",
      "10906856     6      21\n",
      "10906857     6      15\n",
      "\n",
      "[10365683 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def getHours(col):\n",
    "    return datetime.strptime(col.split(' ')[1], '%H:%M:%S').time().hour\n",
    "\n",
    "def getMinutes(col):\n",
    "    return datetime.strptime(col.split(' ')[1], '%H:%M:%S').time().minute\n",
    "\n",
    "print \"Creating hour feature...\"\n",
    "hourFeature = cleandata[\"tpep_pickup_datetime\"].apply(getHours)\n",
    "\n",
    "print \"Creating minute feature...\"\n",
    "minuteFeature = cleandata[\"tpep_pickup_datetime\"].apply(getMinutes)\n",
    "\n",
    "df1 = hourFeature.to_frame(name='hour')\n",
    "df2 = minuteFeature.to_frame(name='minute')\n",
    "time_data = pd.concat([df1, df2], join='outer', axis=1)\n",
    "\n",
    "print time_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all of the columns except for the pickup, dropoff, and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be187f616404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcleandata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pickup_longitude\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pickup_latitude\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mjoin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleandata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dropoff_longitude\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dropoff_latitude\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "X = pd.concat([cleandata[[\"pickup_longitude\", \"pickup_latitude\"]], time_data],  join='outer', axis=1)\n",
    "y = cleandata[[\"dropoff_longitude\", \"dropoff_latitude\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# xmatrix = X.as_matrix(columns=X.columns)\n",
    "# kmeans_x = KMeans(n_clusters=24, n_jobs=-1, random_state=0).fit(xmatrix)\n",
    "# centroids_x = kmeans_x.predict(xmatrix)\n",
    "# X = np.array([kmeans_x.cluster_centers_[i] for i in centroids_x])\n",
    "\n",
    "kmeans_y = KMeans(n_clusters=24, n_jobs=-1, random_state=0).fit(y)\n",
    "centroids_y = kmeans_y.predict(y)\n",
    "for i, row in y.iterrows():\n",
    "    if i < len(y):\n",
    "        y.set_value(i, \"centroid\", centroids_y[i])\n",
    "y = y[[\"centroid\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "n_samples = Xtrain.shape[0]\n",
    "n_features = Xtrain.shape[1]\n",
    "\n",
    "print Xtrain.shape\n",
    "max_samples = 100\n",
    "if Xtrain.shape[0] > max_samples:\n",
    "#     rows = random.sample(range(len(Xtrain)), max_samples)\n",
    "    rows = random.sample(Xtrain.index, max_samples)\n",
    "    Xtrain = Xtrain.ix[rows]\n",
    "    ytrain = ytrain.ix[rows]\n",
    "print Xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plt.rcParams['agg.path.chunksize'] = 100000\n",
    "# plt.plot(Xtrain[\"pickup_longitude\"], Xtrain[\"pickup_latitude\"], 'ro', markersize=2, markeredgewidth=0)\n",
    "# plt.grid(True)\n",
    "# plt.axis([-74.4, -73.5, 40.55, 40.9])\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(ytrain[\"dropoff_longitude\"], ytrain[\"dropoff_latitude\"], 'ro', markersize=2, markeredgewidth=0)\n",
    "# plt.grid(True)\n",
    "# plt.axis([-74.4, -73.5, 40.55, 40.9])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None, verbose=0):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func, verbose=verbose)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds, verbose=verbose)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.cv_results_, gs.scorer_\n",
    "    print \"Best score: \", gs.best_score_\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "clf = AdaBoostClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [50],  \n",
    "#     \"max_features\": [\"auto\"],\n",
    "#     \"max_depth\": [50]\n",
    "# }\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\": [50],\n",
    "    \"learning_rate\": [1]\n",
    "}\n",
    "\n",
    "best = cv_optimize(clf, parameters, Xtrain, ytrain.as_matrix().flatten(), n_folds=5, score_func='neg_mean_squared_error', verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "reg = best.fit(Xtrain, ytrain)\n",
    "training_accuracy = reg.score(Xtrain, ytrain)\n",
    "test_accuracy = reg.score(Xtest, ytest)\n",
    "print \"############# based on standard predict ################\"\n",
    "print \"R^2 on training data: %0.4f\" % (training_accuracy)\n",
    "print \"R^2 on test data:     %0.4f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best.predict([[-73.990371704101563, 40.734695434570313]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
